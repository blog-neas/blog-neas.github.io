<!doctype html>
<html class="no-js" lang="en-US">
  <head>
    <meta charset="utf-8">
    <title>Text Mining with R: cleaning and preparing data | Lucio Palazzo</title>
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="preload" href="https://blog-neas.github.io/fonts/academicons.ttf?v=1.7.0" as="font">
    <link rel="preload" href="https://blog-neas.github.io/fonts/fontawesome-webfont.woff2?v=4.6.34Cas" as="font">
    <link href="https://fonts.googleapis.com/css?family=Fira+Sans|Merriweather" rel="stylesheet">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hack-font@3/build/web/hack-subset.css">
    <link rel="stylesheet" href="https://blog-neas.github.io/css/foundation.min.css">
    <link rel="stylesheet" href="https://blog-neas.github.io/css/stackoverflow-light.min.css">
    <link rel="stylesheet" href="https://blog-neas.github.io/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://blog-neas.github.io/css/academicons.min.css">
    <link rel="stylesheet" href="https://blog-neas.github.io/css/finite.min.css">
    <link rel="stylesheet" href="https://blog-neas.github.io/css/kube.min.css">
    <link rel="stylesheet" href="https://blog-neas.github.io/css/robjhyndman.min.css">
    
<script>
(function(m,a,i,l,e,r){ m['MailerLiteObject']=e;function f(){
var c={ a:arguments,q:[]};var r=this.push(c);return "number"!=typeof r?r:f.bind(c.q);}
f.q=f.q||[];m[e]=m[e]||f.bind(f.q);m[e].q=m[e].q||f.q;r=a.createElement(i);
var _=a.getElementsByTagName(i)[0];r.async=1;r.src=l+'?v'+(~~(new Date().getTime()/1000000));
_.parentNode.insertBefore(r,_);})(window, document, 'script', 'https://static.mailerlite.com/js/universal.js', 'ml');

var ml_account = ml('accounts', '3217732', 'q9y4a1d8i3', 'load');
</script>




<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-H7D1R9SXCS');
</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-H7D1R9SXCS"></script>






</head>
  <body>
    <header>
      <nav class="nav-bar">
	
	  <div class="title-bar" data-responsive-toggle="site-menu" data-hide-for="medium">
	    <button class="site-hamburger" type="button" data-toggle>
	      <i class="fa fa-bars fa-lg" aria-hidden="true"></i>
	    </button>
	    <div class="title-bar-title site-title">
	      <a href="https://blog-neas.github.io/"  style="color: #b3cde0">Lucio Palazzo</a>
	    </div>
	    <div class="title-bar-right pull-right">
	      


	    </div>
	  </div>

	  
	    <div class="top-bar" id="site-menu" >
	      <div class="top-bar-title show-for-medium site-title">
		<a href="https://blog-neas.github.io/"  style="color: #b3cde0;">Lucio Palazzo</a>
	      </div>
	      <div class="top-bar-left">
		<ul class="menu vertical medium-horizontal">
		  
		  
		  <li><a href="https://blog-neas.github.io/en/blog-neas/">NeaS blog</a></li>
		  
		  <li><a href="https://blog-neas.github.io/en/publications/">Publications</a></li>
		  
		  <li><a href="https://blog-neas.github.io/en/seminars/">Seminars</a></li>
		  
		  <li><a href="https://blog-neas.github.io/en/teaching/">Teaching</a></li>
		  
		  <li><a href="https://blog-neas.github.io/en/research-team/">Research team</a></li>
		  
		  <li><a href="https://blog-neas.github.io/it/"><img width='20' height='20' src='https://blog-neas.github.io/img/it.png' ></a></li>
		  
		</ul>
	      </div>
	      <div class="top-bar-right show-for-medium">
		


	      </div>
	    </div>
	  
	</nav>
    </header>
    <main>
      

<div class="wrapper">
<div class="units-row" style='margin-bottom: 0px;'>
<div class="unit-20">&nbsp;</div>
<div class="unit-70"><h1>Text Mining with R: cleaning and preparing data</h1></div>
</div>
<div class="units-row">
  <div class="unit-20 dateblock" style='text-align: right;'><h4 style='padding: .8ex 0px .8ex 0px;'><a href="https://blog-neas.github.io/en/blog-neas">NeaS Blog</a></h4>
    <div class="post-metadata">
  <span class="post-date">
    <time datetime="2022-02-01 00:00:00 &#43;0000 UTC" itemprop="datePublished">1 February 2022</time>
  </span>
  
  </span>
  
  
  
  <span class="post-tags">
    <p><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="https://blog-neas.github.io/en/categories/pls">PLS</a>,
    
    
    
    <a class="post-tag" href="https://blog-neas.github.io/en/categories/text-mining">Text Mining</a>,
    
    
    <a class="post-tag" href="https://blog-neas.github.io/en/categories/data-cleaning">Data Cleaning</a>,
    
    
    <a class="post-tag" href="https://blog-neas.github.io/en/categories/word-cloud">Word Cloud</a>,
    
    
    <a class="post-tag" href="https://blog-neas.github.io/en/categories/tutorial">Tutorial</a>
    
  </span>
  
  
</div>

  </div>
<div class="unit-70">

  
<script src="https://blog-neas.github.io/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<script src="https://blog-neas.github.io/rmarkdown-libs/kePrint/kePrint.js"></script>
<link href="https://blog-neas.github.io/rmarkdown-libs/lightable/lightable.css" rel="stylesheet" />


<p>This is the first post of a series intented to present an overview of the steps involved in undertaking text and data mining, from the data preparation to the sentiment analysis.
This is an excerpt of the online seminar that was held as part of the Summer School for the <em>Plan for Science Degrees</em> (<em>Piano di Lauree Scientifiche</em>, PLS) promoted by the University of Naples Federico II.
Participants consisted of secondary school students and early university students. R software was used for the statistical analyses.
In this article I’ll introduce the first steps to take to preprocess textual data.</p>
<blockquote>
<p>Text expresses a vast, rich range of information, but encodes this information in a form that is difficult to decipher automatically.</p>
<p><span class="citation"><a href="#ref-hearst1999untangling" role="doc-biblioref">Hearst</a> (<a href="#ref-hearst1999untangling" role="doc-biblioref">1999</a>)</span></p>
</blockquote>
<p>Text mining is the automated process of selecting and analysing texttual data for the purpose to find patterns, extract information and perform semantic analysis.
Some of the common text mining tasks are text classification, text clustering, creation of granular taxonomies, document summarisation, entity extraction, and sentiment analysis.</p>
<p>The main advantage of text mining is that text can be found (nearly) everywhere, some examples are:</p>
<ul>
<li>Medical records</li>
<li>Product reviews</li>
<li>Social posts (Facebook, Twitter, etc.)</li>
<li>Book recommendations</li>
<li>Legislation, court decisions</li>
<li>Emails</li>
<li>Websites</li>
</ul>
<p>However, text data is ‘dirty’ and unstructured, meaning that there is no feature vector representation and we have to take into account for:</p>
<ul>
<li>Linguistic structure</li>
<li>Language</li>
<li>Relationships between words</li>
<li>Importance of words</li>
<li>Negations, etc.</li>
<li>Grammatical, spelling, abbreviations, synonyms, homographs</li>
</ul>
<p>More importantly, we have to consider that text is intended for communication between people: context and syntax matter! See for instance <span class="citation"><a href="#ref-van2016exploring" role="doc-biblioref">Van Hee, Lefever, and Hoste</a> (<a href="#ref-van2016exploring" role="doc-biblioref">2016</a>)</span>. For this reason, there is no ‘standard’ method; each document requires a dedicated approach.</p>
<div class="alert alert-info">
<p><strong><svg aria-hidden="true" role="img" viewBox="0 0 352 512" style="height:1em;width:0.69em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M96.06 454.35c.01 6.29 1.87 12.45 5.36 17.69l17.09 25.69a31.99 31.99 0 0 0 26.64 14.28h61.71a31.99 31.99 0 0 0 26.64-14.28l17.09-25.69a31.989 31.989 0 0 0 5.36-17.69l.04-38.35H96.01l.05 38.35zM0 176c0 44.37 16.45 84.85 43.56 115.78 16.52 18.85 42.36 58.23 52.21 91.45.04.26.07.52.11.78h160.24c.04-.26.07-.51.11-.78 9.85-33.22 35.69-72.6 52.21-91.45C335.55 260.85 352 220.37 352 176 352 78.61 272.91-.3 175.45 0 73.44.31 0 82.97 0 176zm176-80c-44.11 0-80 35.89-80 80 0 8.84-7.16 16-16 16s-16-7.16-16-16c0-61.76 50.24-112 112-112 8.84 0 16 7.16 16 16s-7.16 16-16 16z"/></svg> Example.</strong> There is a huge difference between the sentences ‘<em>Even the sun sets in paradise</em>’ and ‘<em>The sun sets even in paradise</em>’ or, again, between ‘<em>she only told me she loved him</em>’ and ‘<em>she told me she loved only him</em>,’ but for a computer those pairs of sentences are almost identical.</p>
</div>
<p>In general, text is stored in an unstructured way. Pre-processing the raw data to transform unstructured data into structured data is the first task to overcome, making it possible to analyse vast collections of text documents.</p>
<table>
<colgroup>
<col width="47%" />
<col width="52%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>Structured data</strong></th>
<th align="center"><strong>Unstructured data</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Data is organised in a defined format, allowing it to be easily parsed and manipulated by a computer.</td>
<td align="center">Data has irregularities and ambiguities that make it difficult to process it using traditional softwares.</td>
</tr>
</tbody>
</table>
<!-- **Structured data** -->
<!-- : Data are organised in a defined format, allowing it to be easily parsed and manipulated by a computer.  -->
<!-- **Unstructured data** -->
<!-- : Data has irregularities and ambiguities that make it difficult to process it using traditional softwares. -->
<p>Thus, the first step involves pre-processing the raw data to transform unstructured data into structured data, turning a collection of documents into a feature-vector representation. In general, a collection of <strong>documents</strong> is called <strong>corpus</strong> where each document is composed of individual <strong>tokens</strong> or <strong>terms</strong> (i.e. words).</p>
<p>The structure of each document can be various. Each document can be a full book (e.g. <a href="https://textmining.nu/2018/10/29/text-mining-the-lord-of-the-rings/">LOTR</a>), a chapter, some pages, few sentences (e.g. Twitter posts) or even a single sentence.
The process involving the conversion of this kind of unstructred data to a structured feature vector is called <strong>featurization</strong>.</p>
<p>In our case, each document is represented by a short answer; we asked participants of the seminar to answer (using a Google Form) to the question ‘what would you like to do after graduation?’ (‘Cosa vorresti fare dopo il diploma?’),
setting an open answer with fixed limit of 200 letters.</p>
<p>During the PLS seminar we gathered a total of 147 answers, the original dataset has been translated in english and it is available <a href="https://blog-neas.github.io/data/pls2021_eng.csv">here</a> (<a href="https://blog-neas.github.io/data/pls2021.csv">here</a> you can find the original version).</p>
<div id="text-mining-with-r" class="section level2">
<h2>Text Mining with R</h2>
<p>The <code>tm</code> package is required for the text mining functions, while some stemming procedures need the use of <code>SnowballC</code> package.</p>
<pre class="r"><code>rawdata &lt;- read.csv(&quot;pls2021_eng.csv&quot;,sep=&quot;;&quot;)
head(rawdata)</code></pre>
<div style="border: 1px solid #ddd; padding: 5px; overflow-x: scroll; width:100%; ">
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
ID
</th>
<th style="text-align:left;">
answer
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
University of Veterinary Medicine
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
University
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:left;">
University - Informatics
</td>
</tr>
<tr>
<td style="text-align:right;">
4
</td>
<td style="text-align:left;">
University
</td>
</tr>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:left;">
I would like to enroll in a physics or aerospace engineering degree program
</td>
</tr>
</tbody>
</table>
</div>
<p>The function <code>SimpleCorpus</code> transforms raw texts, initially stored as a vector, into a corpus.</p>
<pre class="r"><code>corpus &lt;- SimpleCorpus(VectorSource(rawdata[,2]),control = list(language=&quot;en&quot;))</code></pre>
<p>When data is large and more structured, other functions are suggested (i.e. <code>VCorpus</code>, <code>PCorpus</code>) to boost performance and minimize memory pressure.
With <code>str(corpus)</code> we can inspect the newly defined data structure.</p>
<pre class="r"><code>str(corpus)</code></pre>
<pre><code>## Classes &#39;SimpleCorpus&#39;, &#39;Corpus&#39;  hidden list of 3
##  $ content: chr [1:147] &quot;University of Veterinary Medicine&quot; &quot;University &quot; &quot;University - Informatics&quot; &quot;University &quot; ...
##  $ meta   :List of 1
##   ..$ language: chr &quot;en&quot;
##   ..- attr(*, &quot;class&quot;)= chr &quot;CorpusMeta&quot;
##  $ dmeta  :&#39;data.frame&#39;: 147 obs. of  0 variables</code></pre>
<div id="pre-processing-data" class="section level3">
<h3>Pre-processing data</h3>
<p>Depending on the task, there may be several methods that we can take to standardise the text. Some pre-processing techniques are depicted as follows.</p>
<p><strong>Normalisation:</strong> It is the first attempt to reduce the number of unique tokens present in the text, removing the variations in a text and also cleaning for the redundant information. Among the most common approaches it is worth to consider the reduction of every characters to lower case, misspelling conversion and special characters removal.</p>
<p>Usually, a typical normalization involves the lowercase and deletion of stop words.</p>
<pre class="r"><code>corpus_cl &lt;- tm_map(corpus, tolower)</code></pre>
<p>Additionally, it would be necessary to convert special symbols (i.e. emoticons) and accented characters, that are common in some languages (i.e. in Italian), to their plain version. In this case, there are several techniques that can do the trick, one of the most common is given by changing the original encoding to ASCII with transliteration option (<code>ASCII//TRANSLIT</code>) by using the <code>iconv()</code> function.</p>
<pre class="r"><code>corpus_cl &lt;- tm_map(corpus_cl,iconv,from=&quot;UTF-8&quot;,to=&quot;ASCII//TRANSLIT&quot;)</code></pre>
<p>Sometimes the conversion in ASCII returns the question mark “?” as result, meaning that the algorithm was not able to map the character from the initial encoding to ASCII.</p>
<pre class="r"><code>corpus[116]$content</code></pre>
<pre><code>## [1] &quot;the millionaire 😂&quot;</code></pre>
<pre class="r"><code>corpus_cl[116]$content</code></pre>
<pre><code>## [1] &quot;the millionaire ?&quot;</code></pre>
<p>This kind of error will be corrected in next step, when removing punctuation symbols.</p>
<p><strong>Stopwords:</strong> Text and document classification includes many words which do not contain important significance to be used in classification algorithms (e.g. ‘and,’ ‘about,’ ‘however,’ ‘afterwards,’ ‘again,’ etc.). The most common technique to deal with these words is to remove them from the documents.</p>
<pre class="r"><code>corpus_cl &lt;- tm_map(corpus_cl, removeWords, c(stopwords(&#39;en&#39;)))

corpus_cl[1:5]$content</code></pre>
<pre><code>## [1] &quot;university  veterinary medicine&quot;                                
## [2] &quot;university &quot;                                                    
## [3] &quot;university - informatics&quot;                                       
## [4] &quot;university &quot;                                                    
## [5] &quot;  like  enroll   physics  aerospace engineering degree program &quot;</code></pre>
<p>The corpus can be additionally filtered by using the following functions.</p>
<pre class="r"><code># remove numbers
corpus_cl &lt;- tm_map(corpus_cl, removeNumbers)
# remove punctuation
corpus_cl &lt;- tm_map(corpus_cl, removePunctuation)
# set the dictionary and remove additional words/acronyms
drop &lt;- c(&quot;cuz&quot;)
corpus_cl &lt;- tm_map(corpus_cl,removeWords,drop)
# remove extra white spaces
corpus_cl &lt;- tm_map(corpus_cl, stripWhitespace)

corpus[117]$content</code></pre>
<pre><code>## [1] &quot;My biggest dream is to be a forensic anthropologist, but I am very afraid of not being able to do it and of making the wrong choice, cuz I would also like to do criminology or be a detective.&quot;</code></pre>
<pre class="r"><code>corpus_cl[117]$content</code></pre>
<pre><code>## [1] &quot; biggest dream forensic anthropologist afraid able making wrong choice also like criminology detective&quot;</code></pre>
<p>Stopwords removal, as well as other procedures (see stemming below), is clearly language-dependent: each language has a specific list of symbols and special characters.</p>
<p><strong>Lemmatization/Stemming:</strong> replace the suffix of a word with a different one or removes the suffix of a word completely to get the basic word form (<em>lemma</em>).</p>
<p><span class="math display">\[\begin{align*}
 \text{write, writing} &amp; \quad \Longrightarrow \quad &amp; \text{writ}
\end{align*}\]</span></p>
<pre class="r"><code>corpus_cl &lt;- tm_map(corpus_cl, stemDocument,language = &quot;it&quot;)</code></pre>
<p>In some cases, to avoid ambiguization, the replacement is slightly different from the original word. The final result is different from the initial corpus.</p>
<pre class="r"><code>corpus[1:5]$content</code></pre>
<pre><code>## [1] &quot;University of Veterinary Medicine&quot;                                           
## [2] &quot;University &quot;                                                                 
## [3] &quot;University - Informatics&quot;                                                    
## [4] &quot;University &quot;                                                                 
## [5] &quot;I would like to enroll in a physics or aerospace engineering degree program &quot;</code></pre>
<pre class="r"><code>corpus_cl[1:5]$content</code></pre>
<pre><code>## [1] &quot;university veterinary medicin&quot;                        
## [2] &quot;university&quot;                                           
## [3] &quot;university informatics&quot;                               
## [4] &quot;university&quot;                                           
## [5] &quot;lik enroll physics aerospac engineering degre program&quot;</code></pre>
</div>
<div id="document-term-matrix" class="section level3">
<h3>Document-Term Matrix</h3>
<p>After pre-processing, the data have the form of a ‘clean’ corpus, consisting of a collection of n = 147 vectors, each of them containing a collection of <span class="math inline">\(p_i\)</span> words, with <span class="math inline">\(i=1, \ldots, n\)</span>.
It is possible to define a <strong>document-term matrix</strong> (DTM), a <span class="math inline">\(n\times m\)</span> matrix where rows correspond to documents in the collection and columns correspond to the number of unique tokens of the corpus. This representation describes then the frequency of terms that occur in a collection of documents.
Alternatively, It is also common to use the transposed version, also called <strong>term-document matrix</strong> (TDM).</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Term 1</th>
<th>Term 2</th>
<th><span class="math inline">\(\cdots\)</span></th>
<th>Term <span class="math inline">\(m\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Doc 1</td>
<td><span class="math inline">\(d_{1,1}\)</span></td>
<td><span class="math inline">\(d_{1,2}\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(d_{1,m}\)</span></td>
</tr>
<tr class="even">
<td>Doc 2</td>
<td><span class="math inline">\(d_{2,1}\)</span></td>
<td><span class="math inline">\(d_{2,2}\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(d_{2,m}\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
</tr>
<tr class="even">
<td>Doc <span class="math inline">\(n\)</span></td>
<td><span class="math inline">\(d_{n,1}\)</span></td>
<td><span class="math inline">\(d_{n,2}\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(d_{n,m}\)</span></td>
</tr>
</tbody>
</table>
<p>In our case, the DTM is obtained through the use of the <code>DocumentTermMatrix</code> function.</p>
<pre class="r"><code>DTM &lt;- DocumentTermMatrix(corpus_cl)</code></pre>
<p>The resulting DTM has dimension 147 x 298 and the values of the cells correspond to the raw counts of a given term.
Row marginals represent the number of terms in each document while column marginals count how many times each unique term appears in the corpus.</p>
<pre><code>## &lt;&lt;DocumentTermMatrix (documents: 5, terms: 5)&gt;&gt;
## Non-/sparse entries: 8/17
## Sparsity           : 68%
## Maximal term length: 11
## Weighting          : term frequency (tf)
## Sample             :
##     Terms
## Docs aerospac informatics medicin university veterinary
##    1        0           0       1          1          1
##    2        0           0       0          1          0
##    3        0           1       0          1          0
##    4        0           0       0          1          0
##    5        1           0       0          0          0</code></pre>
<p>Different schemes for weighting raw counts can be applied, depending on the type of statistical measures to be derived.</p>
<p>Next time, we will start from the DTM to provide some descriptive statistics and generate the word cloud.</p>
</div>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-hearst1999untangling" class="csl-entry">
Hearst, Marti A. 1999. <span>“Untangling Text Data Mining.”</span> In <em>Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics</em>, 3–10.
</div>
<div id="ref-van2016exploring" class="csl-entry">
Van Hee, Cynthia, Els Lefever, and Véronique Hoste. 2016. <span>“Exploring the Realization of Irony in Twitter Data.”</span> In <em>Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC’16)</em>, 1794–99.
</div>
</div>
</div>


      <meta itemprop="wordCount" content="1649">
      <meta itemprop="datePublished" content="2022-02-01">
      <meta itemprop="url" content="https://blog-neas.github.io/en/blog-neas/pls-seminar-one/">

<div class='sans' style="background: #dddddd; padding: 2em; margin-top: 20px;">
<div style="padding-bottom: 1em" >
<p>
  
    <a href="https://blog-neas.github.io/en/blog-neas/pls-seminar-one/">"Text Mining with R: cleaning and preparing data"</a> by <a href="https://blog-neas.github.io/en/authors/">Lucio Palazzo</a>&nbsp;/&nbsp;<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>
  
</p>
<div class="share-box">
  <ul class="share">
    <li>
      <a class="facebook" href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fblog-neas.github.io%2fen%2fblog-neas%2fpls-seminar-one%2f" target="_blank">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="twitter" href="https://twitter.com/intent/tweet?text=Text%20Mining%20with%20R%3a%20cleaning%20and%20preparing%20data. https%3a%2f%2fblog-neas.github.io%2fen%2fblog-neas%2fpls-seminar-one%2f from @robjhyndman" target="_blank">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fblog-neas.github.io%2fen%2fblog-neas%2fpls-seminar-one%2f&amp;title=Text%20Mining%20with%20R%3a%20cleaning%20and%20preparing%20data" target="_blank">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo" href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fblog-neas.github.io%2fen%2fblog-neas%2fpls-seminar-one%2f&amp;title=Text%20Mining%20with%20R%3a%20cleaning%20and%20preparing%20data" target="_blank">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email" href="mailto:?subject=Text%20Mining%20with%20R%3a%20cleaning%20and%20preparing%20data&amp;body=https%3a%2f%2fblog-neas.github.io%2fen%2fblog-neas%2fpls-seminar-one%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


</div>

    <ul class="pagination" role="navigation" aria-label="Pagination">
      
      <li class="arrow" aria-disabled="true"><a href="https://blog-neas.github.io/en/blog-neas/help/">&laquo; <em>Previous<span class="show-for-sr"> page</span></em>: Help</a></li>
      
      
      <li class="arrow" aria-disabled="true"><a href="https://blog-neas.github.io/en/blog-neas/rpyhtoninstall/"><em>Next<span class="show-for-sr"> page</span></em>: Python installation guide&nbsp;&raquo;</a></li>
      
    </ul>
        
      <a href="https://blog-neas.github.io/en/blog-neas/">All NeaS posts by date</a>
      
      
</div>

<span style='font-family: Carlito'>
 <div id="disqus_thread"></div>
<script type="text/javascript">

(function() {
    
    
    if (window.location.hostname == "localhost")
              return;

    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    var disqus_shortname = 'palazzolucio';
    
    
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    
    
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

</span>

  </div>
  </div></div>

    </main>
    <footer class="whatisthis">
  <hr class='separator'/>
  <span style="font-family: Carlito, sans; font-size: 0.9em; line-height: 1.05em;">
  <div class="row">
    <div class="column small-12 medium-4">
      <figure class='image-left'>
      <a href="https://blog-neas.github.io/" style="border-bottom: none;">
      	<img src="https://blog-neas.github.io/img/fotoscholar_mod.png" alt="Portrait of the author" class='avatar' style="max-width: 100%;">
      </a>
      </figure>
      <p>Lucio&nbsp;Palazzo <span style="font-size: 10pt;">PhD</span> is Junior Associate Professor of the <a href="http://www.scienzepolitiche.unina.it">LabStat, DiSP</a> at <a href="http://www.unina.it/en_GB/home">University of Naples Federico II</a>, Napoli.</p>
      
      <p><em><a href="https://blog-neas.github.io/en/about/">About me</a></em></p>
      
      
    </div>
    <div class="column small-12 medium-4">
      
      <h4 id="contact">Contact</h4>
      <ul class="fa-ul">
	
	<li><i class="fa-li fa fa-university" style="color:#03396c;font-size:80%;padding-top:6px;"></i><a href="https://www.labstat.it/">LabStat - Statistics Laboratory, Department of Political Sciences, Federico II University, L. Rodinò 22 road - 80138 Napoli (NA), Italy.</a></li>
	
	<li><i class="fa-li fa fa-envelope" style="color:#03396c;font-size:80%;padding-top:6px;"></i><a href="mailto:lucio.palazzo@unina.it">lucio.palazzo@unina.it</a></li>
	
	<li><i class="fa-li ai ai-google-scholar" style="color:#03396c;font-size:80%;padding-top:6px;"></i><a href="https://scholar.google.com/citations?user=jyhrTYkAAAAJ">Google Scholar</a></li>
	
	<li><i class="fa-li ai ai-researchgate" style="color:#03396c;font-size:80%;padding-top:6px;"></i><a href="https://www.researchgate.net/profile/Lucio-Palazzo">ResearchGate</a></li>
	
	<li><i class="fa-li fa fa-github-alt" style="color:#03396c;font-size:80%;padding-top:6px;"></i><a href="https://github.com/blog-neas">LP-NeaS</a> on GitHub</li>
	
	<li><i class="fa-li ai ai-orcid" style="color:#03396c;font-size:80%;padding-top:6px;"></i><a href="https://orcid.org/0000-0001-7529-4689">0000-0001-7529-4689</a> on OrcID</li>
	
      </ul>
    </div>

  <div class="column small-12 medium-4">
  <h4>Search</h4>
  <a id="searchsite">
  	<form method="get" action="https://duckduckgo.com/">
	  <label for="search-field" class="show-for-sr">Search the site</label>
	  <input type="search" name="q" maxlength="255" placeholder="Search the site" id="search-field">
	  <input type="hidden" name="sites" value="https://blog-neas.github.io/"/>
	  <input type="hidden" name="k7" value="#faf8f8"/>
	  <input type="hidden" name="kj" value="#b33"/>
	  <input type="hidden" name="ky" value="#fafafa"/>
	  <input type="hidden" name="kx" value="b"/>
	  <input type="hidden" name="ko" value="-1"/>
	  <input type="hidden" name="k1" value="-1"/>
	</form>
  </a>

  
  <hr style="border-top:5px solid #faf8f8;"/>
  
  
  
    
  


  
  </div>
  </div>
  </span>
</footer>

    <div class="endofpage">
    <footer id="footer">
    <section class="wrapper small">Inspired by <a href="https://robjhyndman.com">Rob&nbsp;J&nbsp;Hyndman's</a> blog. &nbsp;&nbsp; &copy;<a href="mailto:lucio.palazzo@unina.it">Lucio Palazzo</a> 2021&ndash;2022.
     &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://blog-neas.github.io/en/index.xml"><img src="https://blog-neas.github.io/img/rss2.png" width=12 align="bottom" alt="RSS icon"  style="padding-top: 0.7ex"></a>
    </section>
    </footer>
    </div>

    <script src="https://blog-neas.github.io/js/jquery.js"></script>
    <script src="https://blog-neas.github.io/js/what-input.js"></script>
    <script src="https://blog-neas.github.io/js/foundation.min.js"></script>
    <script src="https://blog-neas.github.io/js/finite.js"></script>

    
    <script src="//cdn.bootcss.com/highlight.js/11.3.1/highlight.min.js"></script>
    <script src="//cdn.bootcss.com/highlight.js/11.3.1/languages/r.min.js"></script>

    <script>
    hljs.configure({languages: []});
    hljs.initHighlightingOnLoad();
    </script>

    
    
    
    
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <script type='text/javascript' src='https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js'></script>
 </body>
</html>
